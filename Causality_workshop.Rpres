<style type="text/css">
.small-code pre code {
font-size: 0.9em;
}
.footer {
    color: black; background: #E8E8E8;
    position: fixed; top: 90%;
    text-align:center; width:100%;
}
</style>

Causality
========================================================
author: Jim Savage


Causality: motivation
========================================================

We want to draw _causal inference_ from both _experiments_ and
_observational data_
- Causal: how much do I expect $Y$ to change if I vary $X$?
- Inference: How unsure should I be of my findings? 
- Experiments: where we can learn about impact of varying $X$ by, 
er, varying $X$ (RCTs, A/B testing, etc)
- Observational data: where no deliberate experiment has been 
run (surveys, economic data, sales data, etc.)

Causality: meta-motivation
========================================================

- What do data scientists do? 
- What are the easiest things to automate?
- How do data scientists inform strategy?
- My claim is that the last thing data scientists will do is causal research.


Sorts of problems involving causality
========================================================

### No problems with inference

- Analyse results of an experiment (average treatment effects)
- Infer for population based on an experiment on a biased subset (MrP)
- Advise on set-up of A/B tests/randomized control trials
- Use experimental results to rank customers on potential uplift

Sorts of problems involving causality 2
========================================================

### Group differences involving selection-into-treatment

- Do university graduates earn more?
  - Were graduates always going to earn more? 
- School choice, teacher effects, impacts of laws etc. 
  - Pushy parents more likely to send children to "good" schools. 
- Do customers you (passively) market to have a higher probability of buying?
  - Customers already looking!



Sorts of problems involving causality 3
========================================================

### Problems involving endogenous treatment

Endogenous = caused by

- Price vs sales
  - When sales increase, pressure on price is to increase. 
- Basically all finance/macroeconomics
  - An increase in inflation leads RBA board to increase rates
  - An increase in economic activity pushes stock prices higher **and** interest rates higher


Sorts of problems involving causality 4
========================================================

### Endogenous treatment? 

- Marketing uplift
  - Does ad-buy work? Media buyers' decisions and ad spot prices reflect possible uplift for an advertisement. 
  - Qualitative impact? Do changes to your website/call scripts/customer service drive changes in sales?

The issues here come from the fact that managers are intelligent, and do their best for the business. 


Sorts of problems involving causality 5
========================================================

### Competitive focus

- How will your competitors react to your entry/product offering strategies? 
  - Can be difficult, but quite possible; often cost of making assumptions is greater than benefit.
- How will competitors react to your pricing?
  - Much easier, but still difficult. Need a good understanding of causality!


Class discussion
========================================================
  
I want 5 causal problems from your workplace before we can move on.


Why does this stump data scientists? 
========================================================

Looks similar to a predictive problem, but is not. 

### More data? 
- In prediction, more data = better predictions
- In causality, with wrong model, more data = worse estimate

### Out of sample prediction? 
- This is what we do for validation in prediction
- Causal models could have almost no predictive power and still be wonderful. 

### Automatable? 
- No

Outline for today
========================================================

1. Rubin Causal Model (RCM): Now - 10.30
2. Why use Bayesian techniques? 10.45 - 11.15
3. Estimating causal effects using regularized linear models. Bad controls/moderators. Techniques to capture non-linearity. 11.30 - 12.30
4. Lunch 12.30 - 1.30
5. Dealing with unobserved confounders that are fixed at a level of the hierarchy. 1.30-2.30
6. Using natural experiments/instrumental variables to control for unobserved confounders. 2.45 - 3.30
7. An introduction to using machine learning for causal effects. 3.45 - 4.30 (only if we have time)


Terminology
========================================================

### Treatment/Dose
- The thing you want to change: price, ad-spot, medicine, policy, etc. 

### Outcome
- The thing you care about (sales, profits, health, unemployment, etc.)

### Counterfactual
- The state of the world that we never see, where only the treatment has changed. 

### Confounders
- Variables that result in correlation not equalling causation.

Terminology
========================================================
### Controls
- Confounders that we observe/measure

### Endogenous variables
- Variables that are caused by other variables in the system (both observed and unobserved)

### Exogenous variables
- Variables that are not caused (or are very loosely caused) by other variables in the systemf

Experimental vs observational data
========================================================

### Experimental data = easy inference
- We have control over the treatment, and know how it was used. 
- Ideally, we have control over the procedures used in the experiment

### Observational data = hard inference
- We have no input into the data creation.
- Still want to draw inference. 


What is causality? 
========================================================

### The potential outcomes framework

Interested in causal relationship on $Y$ from change in treatment from $T1$ to $T2$? 

The treatment is administered at some time $t$ and both oucomes are measured at some time after the treatment $t+ s$

- Call $Y_{T1}$ the outcome under $T1$
- Call $Y_{T2}$ the outcome under $T2$

The **Treatment effect** is $Y_{T2}$ - $Y_{T1}$. 

This is called **Rubin Causality**, or **The potential outcomes framework**. You can think of it as the difference between parallel universes, where only the treatment has changed. 

What is causality? 
========================================================


```{r, echo = F}
library(dplyr); library(pander); library(knitr)
TEs <- data.frame(Individual = 1:5, Y_T1 = c(3, 5, 5,3,7), Y_T2 = c(6, 5, 6, 2, 8)) %>%
  mutate(`Individual treatment effect` = Y_T2 - Y_T1)

TEs %>% kable()
```


What is causality? 
========================================================

Things to note: 
- This is a theoretical model! We can't observe both treated and 
untreated states of the world
- Only the treatment _and anything the treatment affects_ has changed
- Not all people have the same treatment effect

Are these effects free of luck polution? A great philosophical question. 

The fundamental problem of causal inference
========================================================

### The potential outcomes framework
The problem is that we observe either $Y_{t1}$ *or* $Y_{t2}$. 

```{r, echo = F}
library(dplyr); library(pander); library(knitr)
data.frame(Individual = 1:5, Y_t1 = c(NA, NA, 5,3,7), Y_t2 = c(6, 5, NA, NA, NA)) %>% kable
```

Why can't I just predict the counterfactual?
========================================================

- If the underlying structure that causes the treatment is correlation with the variables in your model, your predictions will be biased. 
  - University and income
- Sometimes you can! 
  - So long as there are no big unobserved confounders. 

Average treatment effects (ATE)
========================================================

```{r, echo = F}
TEs <- data.frame(Individual = 1:5, Y_T1 = c(3, 5, 5,3,7), Y_T2 = c(6, 5, 6, 2, 8)) %>%
  mutate(`Individual treatment effect` = Y_T2 - Y_T1)

TEs %>% kable()
```

Average treatment effects is the average of `individual treatment effects`. 

```{r}
mean(TEs$`Individual treatment effect`)
```


Average treatment effects (ATE)
========================================================

Is this what we always want to estimate? 


Average treatment effects (ATE)
========================================================

- Tells us the average of treatment effects across a broad population
- We might be interested in a much narrower population, or a marginal population

For example: the ATE of a blood-pressure medication would include the
treatment effects on people with healthy blood pressure (treatment effect
might be much smaller). But we want to know the treatment effect for
the relevant population (those with high blood pressure)

Average treatment effects on the treated (ATET)
========================================================
class: small-code 

```{r, echo = F}
TEs2 <- data.frame(Individual = 1:5, Y_T1 = c(3, 5, 5,3,7), Y_T2 = c(6, 5, 6, 2, 8)) %>%
  mutate(`Individual treatment effect` = Y_T2 - Y_T1, 
         `Treated?` = c(1, 1, 0, 0, 0))

TEs2 %>% kable()
```

ATET does what the can says
```{r}
mean(TEs2$`Individual treatment effect`[TEs2$`Treated?`==1])
```

Within-strata/Group treatment effects
========================================================
class: small-code 

Often it can be helpful to calculate treatment effects within groups

```{r, echo = F}
TEs2 <- data.frame(Individual = 1:5, Y_T1 = c(3, 5, 5,3,7), Y_T2 = c(6, 5, 6, 2, 8)) %>%
  mutate(`Individual treatment effect` = Y_T2 - Y_T1, 
         `Group` = c("a", "b", "a", "b", "a"))

TEs2 %>% kable()
```

```{r}
TEs2 %>% group_by(Group) %>% summarise(GATE = mean(`Individual treatment effect`))
```


Local or Marginal ATE (LATE)
========================================================
class: small-code 

- Often, we are interested in knowing what the treatment effect
would be on a group of people who are encouraged to accept the treatment. 
- This is most common when we can't force someone to adhere to a treatment, 
but they can be encouraged. 

In this case, we can divide population into: 
- *Always takers*
- *Never takers*
- *Sometimes takers*


Local or Marginal ATE (LATE)
========================================================
class: small-code 

```{r, echo = F}
TEs2 <- data.frame(Individual = 1:5, Y_T1 = c(3, 5, 5,3,7), Y_T2 = c(6, 5, 6, 2, 8)) %>%
  mutate(`TE` = Y_T2 - Y_T1, 
         `Sometimes taker` = c(0, 1, 1, 0, 1))

TEs2 %>% kable()
```

```{r}
TEs2 %>% filter(`Sometimes taker`==1) %>% summarise(mean(TE))
```

The treatment assignment mechanism
========================================================

The Rubin Causal Model is completed by the `treatment assignment mechanism`. 

$$
p(T\, |\, X, Y_{T1}, Y_{T2})
$$

Which simply asks _does the probability of receiving the treatment depend on
the known characteristics of each unit, or the treatment effect itself? 

If 

$$
p(T\, |\, X, Y_{T1}, Y_{T2}) = p(T\, |\, X)
$$

Then the model is said to be _unconfounded_. 


The treatment assignment mechanism
========================================================

### Where is this useful?

- Perhaps we want to run an experiment, but it's costly to run
and there's little point in running on those who aren't the tarket market. 
- Perhaps we could run an experiment where some groups are more likely to 
receive the treatment than others. 
- If we condition the probability of receiving the treatment on
known covariates, we can still do inference. 

Quick break
========================================================

## Coffee!


Some statistical background: random variables
========================================================

A variable is a **random variable** if its value is not 
controlled/deterministic. It is subject to chance. 

We think about the following as random variables: 

- Outcomes
- Parameters
- Latent Variables

A good heuristic: 

**If you don't know the value of something out-of-sample, treat 
it as a random variable**


Some statistical background: Probability density functions
========================================================

A probability density function tells us the relative probability
of observing certain values of a random variable. 

- We denote the density of random variable $X$ with $p(X)$
- $p()$ is *overloaded*, meaning $p(X)$ could have a different form to $p(Y)$
- The area under the curve $p(X)$ is 1


Some statistical background: Probability density functions
========================================================
class: small-code

```{r, echo = F, cache = F}
library(ggplot2); library(gridExtra)

ggplot() +
  stat_function(fun = "dnorm", n = 2000, aes(x = -5:5)) +
  theme_bw() +
  xlab("x") +
  ylab("Density") +
  ggtitle("Normal")
```
****
```{r, echo = F, cache = T}


ggplot() +
  stat_function(fun = "dlnorm", n = 2000, aes(x = -5:5)) +
  theme_bw() +
  xlab("x") +
  ylab("Density") +
  ggtitle("Log-normal")


```

Some statistical background: Joint densities
========================================================
class: small-code
```{r, echo = F, cache = T}
library(MASS); library(mvtnorm)

tau <- c(1, 2)
mu <- c(0, 2)
omega <- matrix(c(1, 0.5, 0.5, 1), 2, 2)
Sigma <- diag(tau) %*% omega %*% diag(tau)

Y <- data.frame(mvrnorm(1000, mu = mu, Sigma = Sigma))
Y$dens <- apply(Y, 1, dmvnorm, mean = mu, sigma = Sigma)
names(Y) <- c("x", "y", "dens")
Y2 <- data.frame(x = seq(-3, 4, length.out =100), y = seq(-5, 8, length.out =100))

z <- matrix(0,nrow=100,ncol=100)

for (i in 1:100) {
  for (j in 1:100) {
    z[i,j] <- dmvnorm(c(Y2$x[i],Y2$y[j]),
      mean=mu,sigma=Sigma)
  }
}

contour(Y2$x,Y2$y,z, main = "Multivariate normal density")

```

Some statistical background: Joint densities
========================================================
class: small-code
```{r, echo = F, cache = F}
library(plotly); library(ggplot2)

ggplot(Y, aes(x = x, y = y, colour = dens)) + geom_point() +
  theme_bw() +
  ggtitle("Draws from a bivariate normal")

ggplot(Y, aes(x = x, y = y, colour = dens)) + 
  geom_point() +
  theme_bw() +
  ggtitle("Draws from a bivariate normal")

```


Some statistical background: Marginal distributions
========================================================
class: small-code
```{r, echo = F, cache = T}
par(mfrow=c(2, 1))
contour(Y2$x,Y2$y,z, main = "Multivariate normal density")
x <- seq(-3, 4, length.out = 200)
plot(x, dnorm(x), type= "l")
```


Some statistical background: Conditional distribution
========================================================

```{r, echo = F, cache = T}
par(mfrow = c(1, 1))
contour(Y2$x,Y2$y,z, main = "Conditional density is a 'slice'\nof the joint density")
abline(h = 0)
```


Some statistical background: Density
========================================================
```{r, echo = F, cache = T}
library(ggplot2)

ggplot() +
  stat_function(fun = "dnorm", n = 1000, aes(x = -3:3), args = list(mean = 1, sd = 0.5)) +
  theme_bw() +
  xlab("X") +
  geom_linerange(aes(x = .2, ymin = 0, ymax = dnorm(0.2, 1, 0.5)), colour = "red", size = 2) +
  geom_point(aes(x = .2, y = dnorm(0.2, 1, 0.5)), colour = "black", size = 2) +
  geom_linerange(aes(x = 1.5, ymin = 0, ymax = dnorm(1.5, 1, 0.5)), colour = "red", size = 2) +
  geom_point(aes(x = 1.5, y = dnorm(1.5, 1, 0.5)), colour = "black", size = 2) +
  ggtitle("The height of a density curve at a given value of a random\nvariable is that value's density") +
  ylab("Density")
  
```


Some statistical background: Likelihood
========================================================

- For a given density function with fixed parameters, and a fixed
observation of the outcomes $Y$, **Likelihood** is the product of
each data point's density. 
- Because densities are typically small, taking logs of densities 
and summing is prefered in many cases. In this case we have the 
**Log Likelihood**. 

Some statistical background: Likelihood
========================================================

```{r, echo = F, cache = T}
library(ggplot2)
ggplot() +
  stat_function(fun = "dnorm", n = 1000, aes(x = -3:3), args = list(mean = 1, sd = 0.5)) +
  theme_bw() +
  xlab("Y") +
  geom_linerange(aes(x = .2, ymin = 0, ymax = dnorm(0.2, 1, 0.5)), colour = "red", size = 2) +
  geom_linerange(aes(x = 0.9, ymin = 0, ymax = dnorm(0.9, 1, 0.5)), colour = "red", size = 2) +
  geom_linerange(aes(x = 1.5, ymin = 0, ymax = dnorm(1.5, 1, 0.5)), colour = "red", size = 2) +
  geom_label(aes(x = .2, y = dnorm(0.2, 1, 0.5), label = "1"), colour = "black") +
  geom_label(aes(x = 0.9, y = dnorm(0.9, 1, 0.5), label = "2"), colour = "black") +
  geom_label(aes(x = 1.5, y = dnorm(1.5, 1, 0.5), label = "3"), colour = "black") +
  ggtitle("Likelihood of Y for a given parameterization \n= product of pointwise densities") +
  ylab("Density")
  
```



Generative models: Bayes rule
========================================================

Let's call our collection of parameters $\theta$ and our observed heights $y$. 
Bayes rule tells us that 

$$
p(\theta|\, y) = \frac{p(y|\, \theta)\, p(\theta)}{p(y)}
$$

Since $p(y)$ does not depend on $\theta$, we can re-write this in proportional form

$$
p(\theta|y)\propto p(y|\, \theta)\, p(\theta)
$$

Generative models: All we need to do is specify priors and likelihood
========================================================
$$
p(\theta|\, y)\propto p(y|\, \theta)\, p(\theta)
$$

- We have $p(\theta)$---this is what we were using to parameterize the model before. This is called the **prior**
- We have $p(y|\, theta)$---this is the assumed distribution given the parameters. This is the data model for unknown $y$, or the **Likelihood** for fixed $y$. 
- We can use this to estimate our "updated" distribution for the parameters: $p(\theta|\, y)$. This is the **posterior**

Generative models: All we need to do is specify priors and likelihood
========================================================

- If you can form priors for your parameters and come up with a conditional density for your data, Stan will help you estimate the posterior. 
- We can use priors to help us incorporate information not in the data. 


Part 3: Unconfounded models & observed confounders
========================================================

- Causal diagrams
- The experimental ideal. Why do experiments work?
- Thinking about experiments from perspective of Rubin
- Estimating treatment effects with regression
- Incorporating control variables
- Bad controls

Causal diagrams
========================================================

![An unconfounded causal path](unconfounded_causal_diagram.png)

Causal diagrams
========================================================

![A causal network](CN_1.png)


The experimental ideal
========================================================

### Randomised Control Trial

Idea: 
- If we randomly allocate the treatment, unobserved confounders will be equally distributed between treatment and control groups
  - Randomised access to education/presitigious courses
  - Randomised roll-out of aid programs (JPAL)
  - Randomised marketing

A-B testing in practice
========================================================

In commerce, RCTs are called A-B tests

- Have a "treatment" group A, and "control" group B. 
- Units must be randomly allocated across groups (at least random, conditional on their characteristics)
- Observe differences between groups. This is estimate of the **Average Treatment Effect** (ATE)
- Can have multiple groups, so long as they're large enough. 

### Excellent practice

And when you can't do an A-B test? 
========================================================

- Some treatments are very expensive (entry/new products)
- Others are unethical (education/some aid)
  - If some are going to miss out anyway, why not randomise who misses out? 

Example in rstanarm
========================================================

Experiment
- Across three different `replicates` (three patches)
- Divide plants into groups (treatment, control)
- Spray plants with a given `dose` of herbicide
- Watch to see if the plants die

Example in rstanarm
========================================================
class: small-code

```{r, eval = F}
library(rstanarm); library(readr)
setwd("Whereever/you/have/downloaded/class/files")

plant_data <- read_csv("herbicide.csv")
# Run logistic regression
mod <- stan_glm(died ~ dose, family = binomial, data = plant_data, cores = 4)
summary(mod)
```

Regression with controls
========================================================

![A causal network](CN_1.png)


Regression with controls
========================================================

![A causal network](CN_2.png)

Bad controls
========================================================

![Bad controls](Bad_Control.png)


The rule
========================================================

- Run regression 
  - LHS = your dependent variable
  - RHS = your treatment + confounders
  - **Make sure there are no bad controls**
  - Include predictors? Sometimes, but shouldn't make a large impact. 


Session 4
========================================================

What is panel data?
========================================================

- Multiple observations, multiple units
  - Observe many customers over many periods
  - May have to use week 1's skills to put it in this form!
  
```{r, echo = F}
library(dplyr)
data.frame(Individual = rep(c("Nilay", "Lulu"), each = 3), Time = rep(2012:2014, 2), Purchases = c(50, 76, 33, 12, 32, 0), Letters= c(3, 7, 2, 2, 4, 3), Gender = "F", Postcode = rep(c(3057, 3053), each = 3 ), Age = c(34, 35, 36, 19, 20, 21)) %>% kable
```


Why is panel data important? 
========================================================
class: small-code
- What is the causal issue in:

```
model <- lm(purchases ~ Letters + Gender + factor(Postcode) + Age, data = mypanel)
```


Why is panel data important? 
========================================================
class: small-code
- What is the causal issue in:

```
model <- lm(purchases ~ Letters + Gender + factor(Postcode) + Age, data = mypanel)
```
- Unobserved confounders: past managers/marketers may have targeted Nilay more, but that doesn't mean that the marketing *caused* her higher purchases. 
  - Maybe she was more likely to both receive marketing *and* make purchases?
  - Example from Facebook marketing uplift estimates: 
  
  http://www.kellogg.northwestern.edu/faculty/gordon_b/files/kellogg_fb_whitepaper.pdf
  
  
Individual-level "effects"
========================================================

- If we "de-mean" each individual, **we have removed the effect of all unobserved information at the individual level that does not vary over time**. 
  - "de-meaning" is the process of subtracting the average value of the dependent variable for each individual.
  - In the example above, we'd be interested in how an above-average marketing effort would affect Nilay's purchases relative to her average, and Lulu's relative to her average, etc. 
  - This is automated. No need to "de-mean" the data yourself. 
  
  
Introducing the mixed effects model
========================================================

- Mixed effects models make it very easy to pull out individual "effects"
  - Terminology: "effects" are the individual characteristics we never see
 
In a linear model, we have 

\[
y_{i} = \beta_{0} + \beta_{1}x_{1, i} + \beta_{2}x_{2, i} +... + \epsilon_{i}
\]

A panel model has two subscripts: one for the individual $i$, and one for the time, $t$. We can express a model with individual intercepts as

\[
y_{i,t} = \beta_{0,i} + \beta_{1}x_{1, it} + \beta_{2}x_{2, it} +... + \epsilon_{it}
\]


Introducing the mixed effects model
========================================================

```{r, echo = F}
library(ggplot2)
set.seed(42)
petrol_price <- data_frame(Day = rep(c("Saturday", "Tuesday"), 100), price = rnorm(200, 1.32, 0.05))

petrol_price <- petrol_price %>%
  mutate(price = ifelse(Day=="Saturday", price + 0.08, price),
         Sales = 26 - 7*price + ifelse(Day=="Saturday", 5, 0) + rnorm(200, 0, 3))

petrol_price %>% ggplot(aes(x = Sales, y = price)) + geom_point() + geom_point() +
  geom_smooth(method = "lm") +
  theme_bw(base_size = 16) +
  ggtitle("Petrol price and sales\n")
```


Introducing the mixed effects model
========================================================

```{r, echo = F}
petrol_price %>% ggplot(aes(x = Sales, y = price, colour = Day)) + geom_point() + geom_point() +
  geom_smooth(method = "lm") +
  theme_bw(base_size = 16) +
  ggtitle("Petrol price and sales with day effects\n")

```



Benchmarking varying-intercepts/slopes model
========================================================
class: small-code
- We want to estimate the parameter $\beta_1$ in 
\[
\mbox{performance}_{it} = \beta_0 + \beta_1 \mbox{fees}_{it} + \epsilon_{it}
\]


```{r, message = F, eval = F}
library(rstanarm)

load("super_market_share.RData")

# Take a subset for which we have fees

Super_2 <- Super %>% filter(!is.na(Average.fees) & !is.na(performance))

mod2 <- stan_lm(performance ~ Average.fees, 
                data = Super_2, 
                prior = R2(location = 0.3, "mean"), 
                cores = 4)
mod2
```


Benchmarking varying-intercepts/slopes model
========================================================
class: small-code
- We want to estimate the parameter $\beta_1$ in 
\[
\mbox{performance}_{it} = \beta_0 + \beta_1 \mbox{fees}_{it} + \epsilon_{it}
\]


Now add some controls
========================================================
class: small-code

```{r, message = F, eval = F}
library(rstanarm)

load("super_market_share.RData")

# Take a subset for which we have fees

Super_2 <- Super %>% filter(!is.na(Average.fees) & !is.na(performance))

mod3 <- stan_lm(performance ~ Average.fees + lag_perf + Fund_type, 
                data = Super_2, 
                prior = R2(location = 0.3, "mean"), 
                cores = 4)
mod3
```


Now add some controls
========================================================
class: small-code

```{r, message = F, eval = F}

mod4 <- stan_lmer(performance ~ Average.fees + lag_perf + (1 | Fund_name), 
                data = Super_2, 
                cores = 4)
mod4
```


Implementing the varying-intercepts model in R
========================================================
class: small-code
### We can also have varying treatment effects





Relationship to difference-in-differences
========================================================

![DID](Illustration_of_Difference_in_Differences.png)



Session 5
========================================================



Natural experiments: a primer
========================================================

Sometimes we don't need to run an experiment. One exists in our observational data. 

- Arbitrary shifts in policy
  - MySuper and super fees
- Unanticipated weather shifts/plagues/lotteries
  - Fish in NY, draft lottery
- Strikes/abrupt changes in input costs
  - Unemployment diaries in Australia
  - Changes in commodity prices

A good natural experiment
========================================================

- Does a reasonable job at predicting differences in the treatment
- Satisfies the "exclusion restriction"
  - Why is it called the exclusion restriction? 

A good natural experiment
========================================================

![IV](IV.png)

2-stage least squares
========================================================
Idea

- Predict treatment given control variables and instruments
- Use predicted treatment in regression (with controls)

2-stage least squares example
========================================================

```{r, eval = F}
library(dplyr); library(AER)
data("CigarettesSW")

CigarettesSW <- CigarettesSW %>%
  mutate(rprice = price/cpi, # Real price adjusted for inflation
         rincome = income/population/cpi, # Real per-capital income
         tdiff = (taxs - tax)/cpi)

```


2-stage least squares example
========================================================

### ivreg syntax

`dependent_variable ~ endogenous_var + confounders | confounders + instruments`

- Not yet implemented in `rstanarm`, but will be soon. 
- Can code up your own in Stan, example given here: 


2-stage least squares example
========================================================
class: small-code
```{r, eval = F}

# Simple bivariate regression
model1 <- lm(log(packs) ~ log(rprice), data = CigarettesSW)

# Regression with controls
model12 <- lm(log(packs) ~ log(rprice) + log(income) + year, data = CigarettesSW)

model2 <- ivreg(log(packs) ~ log(rprice) + log(rincome) + year | log(rincome) + I(tax/cpi) + year, data = CigarettesSW)
```



2-stage least squares example
========================================================
class: small-code
```{r, eval = F}
Y <- log(CigarettesSW$packs)
X <- data_frame(log_rincome = log(CigarettesSW$rincome), year = CigarettesSW$year)
Z <- CigarettesSW$tax/CigarettesSW$cpi
X_endog <- log(CigarettesSW$rprice)

library(rstan)
stanmodel <- stan("iv_mod_1instrument.stan", 
                  cores  = 4, 
                  data = list(N = nrow(X),
                              P = ncol(X),
                              X = X,
                              X_endog = X_endog,
                              Z = Z,
                              Y = Y), iter = 500)

stanmodel

```


Going over Instrumental Variables again
========================================================

- It is an attempt to find a "natural experiment" in our treatment
- Or an attempt to properly consider the "experiment"
  - Intent to treat
- Idea is to replace **treatment** in our regression with an estimate of the **random component of treatment**.
  - 2SLS: First regression is `treatment ~ instrument + controls`
  - Second regression is `outcome ~ predicted_treatment_from_first_stage + controls`
- We use `ARM::ivreg`


The problem with IV
========================================================

![Problem with IV](Screen Shot 2015-08-18 at 2.51.32 pm.png)

I want to know more
========================================================

### Read this book
![Problem with IV](mm.gif)


Introducing propensity score matching
========================================================

- Why does an experiment work? 
  - The distribution of counfounders---both measured and unmeasured---is equal across treatment and control. 

If we don't have a natural experiment or panel data, then perhaps it is least bad to build a **synthetic control group**. This will mean that our control group and treatment group are similar **on observed confounders**. 

Incomplete overlap
========================================================

![Incomplete overlap](imbalance.png)

So how do we create a matched control? 
========================================================

### "Exact matching" or "complete matching"

- Match each graduate man with a non-graduate man
  - Match each 25 year old graduate man with a 25 year old non-graduate man
      - Match each 25 year old graduate Asian man with a 25 year old non-graduate Asian man
          - ...
- Upside is that you get great balance
- Downside is that you can't match on many confounders. You encounter a "dimensionality problem"



So how do we create a matched control? 
========================================================

### Clustering

- Perform K-nearest-neighbours or some other clustering routine to group together similar people. 
- Estimate "treatment effects" within each cluster

- Good thing is that you'll end up with a fairly balanced control group
- Bad thing is that you will balance on variables that may not matter


We need to "reduce the dimensions"
========================================================

- Difficult to match on many dimensions
- Easy to match on one dimension
- What if we can create a "score" of how similar two people are in terms of their likelihood to get a treatment, based on their characteristics? 
  - If we have a score, we can match on that. 
- We'll call this a **propensity score**. 


Tends to make better control groups
========================================================

![More balance](morebalance.png)


Tends to make better control groups
========================================================
![More balance](morebalanceage.png)


Method
========================================================

1. Build a model that predicts whether someone received the treatment given their (observed) individual characteristics. 
  - The predicted values of this model are the **propensity scores**. 
2. For those **who did** receive the treatment, choose one or many people **who did not** receive the treatment but has a similar propensity score. 
  - Can use many different matching routines (nearest match, "calliper" matching, etc.)
3. Discard unmatched observations
4. Run a regression model on the remainder (treatment + synthetic control)



Does the model estimate the causal effect?
========================================================

### Maybe
- The main assumption is that after controlling for the observed confounders, treatment is as good as random. 
  - Rules out big unobserved confounders. 
- In practice, we include observed covariates because we hope they are correlated with the unobserved ones. 

Does the model estimate the causal effect?
========================================================

### Critiques
- The Smith-Todd critique: If your model of treatment is not **robust** (changes a lot if you include/exclude covariates), your causal estimate will not be robust. 
  - Use regularised GLM for feature selection! 
- Miller Savage Tan critique: Two very different people can have a similar propensity score, and so propensity score matching does not efficiently balance treatment and control groups. 
  - We can use proximity scores from a Random Forest for better matching; has the strengths of exact matching *and* propensity score matching. 



Implementing propensity score matching in R
========================================================
class: small-code
```{r, eval = F}
library(arm)
data("lalonde")

# First model: Predict treatment given demographic characteristics
propensity_model <- glm(treat ~ age + I(age^2) + educ + black + hisp + married + nodegr, 
                        data = lalonde, 
                        family = binomial(link = "logit"))

# Get the propensity scores
lalonde$propensity_score <- predict(propensity_model, type = "response")

# Generate matches
matches <- matching(z = lalonde$treat, score = lalonde$propensity_score)

# Subset the data
lalonde_matched <- lalonde[matches$matched,]

```


Implementing propensity score matching in R
========================================================


```{r, eval = F}

# Run the two models
# Unmatched data
model_unmatched <- lm(re78 ~ treat + . - propensity_score, data = lalonde)
# Matched data
model_matched <- lm(re78 ~ treat + . - propensity_score, data = lalonde_matched)

# What was the original estimate of the treatment effect?
summary(model_unmatched)
# Has it changed? 
summary(model_matched)
```




You should go and learn my method! 
========================================================

![My method](proxmatch.png)

BART and treatment effects
========================================================

- The big push at the moment is to incorporate machine learning
in causal inference. This is one such example. Commonly used by Hill, Green and others. 
- Idea: directly predict the counterfactual. 
- Build up from individual-level treatment effects. 


```{r, echo = F}
library(dplyr); library(pander); library(knitr)
data.frame(Individual = 1:5, Y_t1 = c(NA, NA, 5,3,7), Y_t2 = c(6, 5, NA, NA, NA)) %>% kable
```


BART and treatment effects
========================================================

- BART is a very impressive machine learning algorithm.
- Does feature selection well, incorporates interactions, non-linearity
- Coherent uncertainty (no need to bootstrap)

We can use BART to help find treatment effects by running 
BART on the very simple model

```
outcome ~ controls + treatment
```
- We then generare posterior predictive inference for 
all units at the two levels of treatment considered. 


BART and treatment effects
========================================================
class: small-code
```{r}
library(BayesTree)
load("super_market_share.RData")

Super_2 <- Super %>% 
  dplyr::select(lag_perf, FUM, over_50, female, Fund_type, Average.fees, performance) %>%
  mutate(FUM = log(FUM))

Super_2 <- Super_2[complete.cases(Super_2),]

X <- Super_2 %>% 
  dplyr::select(lag_perf, FUM, over_50, female, Fund_type, Average.fees) %>%
  as.data.frame

X <- model.matrix(~ . - 1, data = X)
X2 <- X %>% as_data_frame %>%
  mutate(Average.fees = Average.fees + 0.1) %>%
  as.data.frame %>% as.matrix

Y <- Super_2$performance
```


BART and treatment effects
========================================================
class: small-code
```{r, eval = F}
bart_model <- bart(x.train = X, y.train = Y, x.test = X2)
plot(bart_model)

pp_sim_train <- bart_model$yhat.train
pp_sim_test <- bart_model$yhat.test
sim_differences <- pp_sim_test - pp_sim_train

dev.off()
hist(apply(sim_differences, 1, mean))


```